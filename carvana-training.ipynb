{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom zipfile import ZipFile\nfrom pathlib import Path\nimport cv2\nfrom PIL import Image\nimport random\nimport wandb\nimport carvana_utils as utils\nimport torch\nfrom torch.utils.data import DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom skimage.transform import resize","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:28:52.099018Z","iopub.execute_input":"2021-09-14T20:28:52.099437Z","iopub.status.idle":"2021-09-14T20:28:52.107995Z","shell.execute_reply.started":"2021-09-14T20:28:52.099405Z","shell.execute_reply":"2021-09-14T20:28:52.106498Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# uncomment to login for weights and biases for logging the training process\n# wandb.login()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:28:52.110274Z","iopub.execute_input":"2021-09-14T20:28:52.110658Z","iopub.status.idle":"2021-09-14T20:28:52.127403Z","shell.execute_reply.started":"2021-09-14T20:28:52.110606Z","shell.execute_reply":"2021-09-14T20:28:52.126474Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# build folders and unzip\nif not os.path.exists(\"./train_images\"):\n    os.makedirs(\"./train_images\")\nif not os.path.exists(\"./train_masks\"):\n    os.makedirs(\"./train_masks\")\n# uncomment below to create test directory\n# if not os.path.exists(\"./test_masks\"):\n#     os.makedirs(\"./test_masks\")\n\nwith ZipFile(\"../input/carvana-image-masking-challenge/train.zip\", \"r\") as zip_:\n    zip_.extractall(path=\"./train_images\")\n    \nwith ZipFile(\"../input/carvana-image-masking-challenge/train_masks.zip\", \"r\") as zip_:\n    zip_.extractall(path=\"./train_masks\")\n\n# uncomment below to unzip test images (many test images make it slow)\n# with ZipFile(\"../input/carvana-image-masking-challenge/test.zip\", \"r\") as zip_:\n#     zip_.extractall(path=\"./test_images\")","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:28:52.163553Z","iopub.execute_input":"2021-09-14T20:28:52.164053Z","iopub.status.idle":"2021-09-14T20:29:06.284644Z","shell.execute_reply.started":"2021-09-14T20:28:52.164021Z","shell.execute_reply":"2021-09-14T20:29:06.283609Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"SEED = 42\nDEVICE = \"cuda\"\nIMG_DIR = \"./train_images/train\"\nMASK_DIR = \"./train_masks/train_masks\"","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:29:06.286415Z","iopub.execute_input":"2021-09-14T20:29:06.286656Z","iopub.status.idle":"2021-09-14T20:29:06.291694Z","shell.execute_reply.started":"2021-09-14T20:29:06.286628Z","shell.execute_reply":"2021-09-14T20:29:06.290812Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"random.seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:29:06.292782Z","iopub.execute_input":"2021-09-14T20:29:06.293046Z","iopub.status.idle":"2021-09-14T20:29:06.303316Z","shell.execute_reply.started":"2021-09-14T20:29:06.292990Z","shell.execute_reply":"2021-09-14T20:29:06.302640Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# filename is e.g. '0d3adbbc9a8b_02.jpg'\nimg_ids = [filename[:-4] for filename in os.listdir(IMG_DIR)]\nrandom.shuffle(img_ids)\n# split validation and training dataset\nval_ids = img_ids[:len(img_ids)//5]\ntrain_ids = img_ids[len(img_ids)//5:]","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:29:06.304462Z","iopub.execute_input":"2021-09-14T20:29:06.304677Z","iopub.status.idle":"2021-09-14T20:29:06.325807Z","shell.execute_reply.started":"2021-09-14T20:29:06.304651Z","shell.execute_reply":"2021-09-14T20:29:06.324943Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# basic data augmentation (albumentation)\ndef get_albums(img_shape, mask_shape):\n    img_albums = A.Compose([\n        A.Resize(img_shape[0], img_shape[1]),\n        ToTensorV2()])\n    mask_albums = A.Compose([\n        A.Resize(img_shape[0], img_shape[1]),\n        ToTensorV2()])\n    return img_albums, mask_albums","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:29:06.327653Z","iopub.execute_input":"2021-09-14T20:29:06.327915Z","iopub.status.idle":"2021-09-14T20:29:06.333906Z","shell.execute_reply.started":"2021-09-14T20:29:06.327885Z","shell.execute_reply":"2021-09-14T20:29:06.332927Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def run_training_unet(save_model=False):\n    # wandb preferences (configurations and initialization)\n    config_defaults = {\n        \"lr\": 1e-4,\n        \"epochs\": 20,\n        \"img_shape\": (512, 512),\n        \"mask_shape\": (512, 512)\n    }\n    wandb.init(project=\"carvana\", config=config_defaults)\n    config = wandb.config\n    \n    # get albumentations\n    img_albums, mask_albums = get_albums(config.img_shape, config.mask_shape)\n    \n    datasets = {\n        \"train\": utils.CarvanaDataset(train_ids, IMG_DIR, MASK_DIR, img_albums, mask_albums),\n        \"val\": utils.CarvanaDataset(val_ids, IMG_DIR, MASK_DIR, img_albums, mask_albums)\n    }\n    dataloaders = {x: DataLoader(datasets[x], batch_size=8,\n                                 num_workers=8, shuffle=x==\"train\")\n                   for x in [\"train\", \"val\"]}\n    model = utils.UNET()\n    model.to(DEVICE)\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n    eng = utils.Engine(model, optimizer, device=DEVICE)\n    \n    best_loss = np.inf\n    \n    for epoch in range(config.epochs):\n        train_loss = eng.train(dataloaders[\"train\"])\n        val_loss, val_dicecoeff = eng.evaluate(dataloaders[\"val\"])\n        print(\"Epoch [{}/{}] Train Loss: {:.4f} Valid Loss: {:.4f} Dice Coeff.: {:.4f}\".format(\n            epoch+1, config.epochs, train_loss, val_loss, val_dicecoeff))\n        if val_loss < best_loss:\n            best_loss = val_loss\n            if save_model:\n                torch.save(model, f\"model.pth\")\n        \n        wandb.log({\n            \"Training loss\": train_loss,\n            \"Validation loss\": val_loss,\n            \"Dice Coefficient\": val_dicecoeff\n        })\n    return best_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:29:06.335220Z","iopub.execute_input":"2021-09-14T20:29:06.335868Z","iopub.status.idle":"2021-09-14T20:29:06.349909Z","shell.execute_reply.started":"2021-09-14T20:29:06.335831Z","shell.execute_reply":"2021-09-14T20:29:06.349036Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# run_training_unet(save_model=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:29:06.351323Z","iopub.execute_input":"2021-09-14T20:29:06.351673Z","iopub.status.idle":"2021-09-14T20:29:06.364558Z","shell.execute_reply.started":"2021-09-14T20:29:06.351631Z","shell.execute_reply":"2021-09-14T20:29:06.363876Z"},"trusted":true},"execution_count":12,"outputs":[]}]}